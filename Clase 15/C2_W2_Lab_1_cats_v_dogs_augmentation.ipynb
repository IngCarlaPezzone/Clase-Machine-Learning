{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W2/ungraded_labs/C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGxCD4mGHHjG"
   },
   "source": [
    "# Lab: ImageDataGenerator, Validación y Aumento de datos\n",
    "\n",
    "En este cuaderno vamos a avanzar en el tratamiento de imágenes reales, vamos a ver la validacion del modelo en cada paso en entrenamiento y finalmente vamos a mejorar el modelo con el aumento de imágenes.\n",
    "\n",
    "Veamos cómo se puede hacer esto en las siguientes secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instale este paquete para utilizar la GPU de Colab para la formación\n",
    "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJJqX4DxcQs8"
   },
   "source": [
    "## Rendimiento de referencia\n",
    "\n",
    "Empezarás con un modelo que es muy eficaz en el aprendizaje de `Gatos vs Perros` sin aumento de datos. Es similar a los modelos anteriores que ha utilizado. Observa que hay cuatro capas convolucionales con 32, 64, 128 y 128 convoluciones respectivamente. El código es básicamente el mismo del laboratorio anterior, por lo que no repasaremos los detalles paso a paso, ya que lo has visto antes.\n",
    "\n",
    "Entrenarás sólo durante 20 épocas para ahorrar tiempo, pero puedes aumentar esta cantidad si lo deseas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJZIF29-dIRv"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DyUfCTgdwa8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Extract the archive\n",
    "zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "zip_ref.extractall(\"tmp/\")\n",
    "zip_ref.close()\n",
    "\n",
    "# Assign training and validation set directories\n",
    "base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub_BdOJIfZ_Q"
   },
   "source": [
    "Colocarás la creación del modelo dentro de una función para que puedas inicializar fácilmente uno nuevo cuando utilices el aumento de datos más adelante en este cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWllK_Wad-Mx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def create_model():\n",
    "  '''Creates a CNN with 4 convolutional layers'''\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation='relu'),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='binary_crossentropy',\n",
    "                optimizer=RMSprop(learning_rate=1e-4),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJPyDEzOqrKB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdqUoF44esR3"
   },
   "outputs": [],
   "source": [
    "# Constant for epochs\n",
    "EPOCHS = 20\n",
    "\n",
    "# Create a new model\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-G0Am4cguNt"
   },
   "source": [
    "A continuación, visualizará la pérdida y la precisión con respecto al conjunto de entrenamiento y validación. De nuevo utilizarás una función de conveniencia para que pueda ser reutilizada más tarde. Esta función acepta un objeto [Historia](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History) que contiene los resultados del método `fit()` que ejecutó anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZWPcmKWO303"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_acc(history):\n",
    "  '''Plots the training and validation loss and accuracy from a history object'''\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vojz4NYXiT_f"
   },
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb81GvNov-Tg"
   },
   "source": [
    "En los resultados anteriores, se puede ver que la precisión de entrenamiento es superior al 90%, y la precisión de validación está en el rango del 70%-80%. Este es un gran ejemplo de _sobreajuste_, lo que significa que puede hacerlo muy bien con imágenes que ha visto antes, pero no tan bien con imágenes que no ha visto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KBz-vFbjLZX"
   },
   "source": [
    "## Aumento de datos\n",
    "\n",
    "Un método sencillo para evitar el sobreajuste es aumentar un poco las imágenes. Si lo piensas, la mayoría de las imágenes de un gato son muy similares: las orejas están arriba, luego los ojos, luego la boca, etc. Cosas como la distancia entre los ojos y las orejas también serán siempre bastante similares. \n",
    "\n",
    "¿Qué pasa si retocas un poco las imágenes?  En eso consiste el aumento de la imagen. Y hay una API que lo hace fácil.\n",
    "\n",
    "Echa un vistazo al [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) que has estado utilizando para reescalar la imagen. Hay otras propiedades en él que puedes usar para aumentar la imagen. \n",
    "\n",
    "```\n",
    "# Updated to do image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "```\n",
    "\n",
    "Estas son sólo algunas de las opciones disponibles. Vamos a repasarlas rápidamente:\n",
    "\n",
    "* `rotation_range` es un valor en grados (0-180) dentro del cual se pueden rotar aleatoriamente las imágenes.\n",
    "* `width_shift` and `height_shift` son rangos (como una fracción de la anchura o la altura total) dentro de los cuales traducir aleatoriamente las imágenes vertical u horizontalmente.\n",
    "* `shear_range` es para aplicar aleatoriamente transformaciones de cizallamiento.\n",
    "* `zoom_range` es para aplicar aleatoriamente el zoom dentro de las imágenes.\n",
    "* `horizontal_flip` es para voltear aleatoriamente la mitad de las imágenes horizontalmente. Esto es relevante cuando no hay supuestos de asimetría horizontal (por ejemplo, imágenes del mundo real).\n",
    "* `fill_mode` es la estrategia utilizada para rellenar los píxeles recién creados, que pueden aparecer después de una rotación o un cambio de anchura/altura.\n",
    "\n",
    "Ejecute las siguientes celdas para ver el impacto en los resultados. El código es similar al de la línea de base, pero la definición de `train_datagen` se ha actualizado para utilizar los parámetros descritos anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK7_Fflgv8YC"
   },
   "outputs": [],
   "source": [
    "# Create new model\n",
    "model_for_aug = create_model()\n",
    "\n",
    "# Este código ha cambiado. Ahora, en lugar de que el ImageGenerator sólo reescalar\n",
    "# la imagen, también rotamos y hacemos otras operaciones\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Train the new model\n",
    "history_with_aug = model_for_aug.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnyRnwopT5aW"
   },
   "outputs": [],
   "source": [
    "# Plot the results of training with data augmentation\n",
    "plot_loss_acc(history_with_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D1hd5fqmJUx"
   },
   "source": [
    "Como se puede ver, la precisión del entrenamiento ha bajado en comparación con la línea de base. Esto es de esperar porque (como resultado del aumento de datos) hay más variedad en las imágenes, por lo que el modelo necesitará más ejecuciones para aprender de ellas. Lo bueno es que la precisión de la validación ya no se estanca y está más en línea con los resultados del entrenamiento. Esto significa que el modelo está funcionando mejor con los datos no vistos. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción con el modelo\n",
    "\n",
    "Ahora eche un vistazo a la ejecución de una predicción utilizando el modelo. Este código le permitirá elegir 1 o más archivos de su sistema de archivos, cargarlos y ejecutarlos a través del modelo, dando una indicación de si el objeto es un caballo o un humano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "    # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = tf.keras.utils.load_img(path, target_size=(150, 150))\n",
    "    x = tf.keras.utils.img_to_array(img)\n",
    "    x /= 255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "      print(fn + \" is a cat\")\n",
    "    else:\n",
    "      print(fn + \" is a dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4B9b6GPnKg1"
   },
   "source": [
    "## Resumen\n",
    "\n",
    "Este ejercicio ha mostrado un sencillo truco para evitar el sobreajuste. Puede mejorar sus resultados de referencia simplemente ajustando las mismas imágenes que ya tiene. La clase `ImageDataGenerator` tiene parámetros incorporados para hacer precisamente eso. Intente modificar los valores un poco más en el `train_datagen` y vea qué resultados obtiene."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W2/ungraded_labs/C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb",
     "timestamp": 1639637705486
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
