{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armando un data set personalizado y haciendo transfer learning\n",
    "En este cuaderno vamos a ver uno de los conceptos mas importantes en deep learning que da enormes posibilidades de desarrollo para proyectos personalizados para cualquier aplicación.\n",
    "Por otro lado, vamos a ver una forma rápida de armar un data set personalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Transfer Learning\n",
    "\n",
    "> “El Transfer Learning, o aprendizaje transferido en español, se refiere al conjunto de métodos que permiten transferir conocimientos adquiridos gracias a la resolución de problemas para resolver otros problemas.”\n",
    "\n",
    "El Transfer Learning ha tenido un gran éxito con el crecimiento del Deep Learning. Frecuentemente, los modelos utilizados en este campo necesitan grandes tiempos de cálculo y muchos recursos. Sin embargo, utilizando como punto de partida modelos pre-entrenados, el Transfer Learning permite desarrollar rápidamente modelos eficaces y resolver problemas complejos de Computer Vision o Natural Language Processing, NLP.\n",
    "\n",
    "En la siguiente figura se aprecia el enfoque tradicional (izquierda) vs el enfoque de Transfer Learning\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./Imagenes/05.png\", style=\"width:90%;\" >\n",
    "</figure>\n",
    "\n",
    "Como vemos, el Transfer Learning se inspira en el proceso natural de aprendizaje.\n",
    "\n",
    "Tomemos el ejemplo de alguien que toca la guitarra y quiere aprender a tocar el piano. Esta persona puede capitalizar sus conocimientos sobre música para aprender a tocar un nuevo instrumento. De la misma manera, un modelo de reconocimiento de automóviles puede ser adaptado para reconocer camiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Sobre cuáles estrategias se apoyan las técnicas de Transfer Learning?\n",
    "\n",
    "El Transfer Learning se basa en una idea simple, la de re explotar los conocimientos adquiridos por otras configuraciones (fuentes), para resolver un problema en particular (objetivos). En este contexto, podemos distinguir diferentes abordajes según lo que se quiere transferir, y cuando y como se realiza la transferencia. En términos generales, podemos distinguir 3 tipos de Transfer Learning:\n",
    "\n",
    "\n",
    "### 1. Aprendizaje por transferencia inductiva o “inductive transfer learning”\n",
    "\n",
    "En este enfoque, el campo de la fuente y el objetivo es el mismo (mismos datos), pero las tareas de fuente y objetivo son diferentes aunque parecidas. La idea consiste entonces en usar los modelos existentes para reducir de manera ventajosa el campo de aplicación de los modelos posibles (sesgo del modelo), como lo ilustra la figura siguiente:\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./Imagenes/06.png\", style=\"width:90%;\" >\n",
    "</figure>\n",
    "\n",
    "Por ejemplo, es posible utilizar un modelo entrenado para la detección de animales en imágenes para construir un modelo capaz de identificar perros.\n",
    "\n",
    "### 2. Aprendizaje por transferencia no supervisada, o “Unsupervised Transfer Learning”\n",
    "Como en el caso del aprendizaje por transferencia inductiva, los campos de la fuente y el objetivo son similares, aunque las tareas son diferentes. Sin embargo, los datos en ambos campos no están etiquetados.\n",
    "\n",
    "Generalmente es más fácil obtener grandes cantidades de datos no etiquetados, a partir de bases de datos y fuentes en la web por ejemplo, que datos etiquetados. Es por esto que la idea de usar el aprendizaje no supervisado combinado con el Transfer Learning ha generado mucho interés.\n",
    "\n",
    "Por ejemplo, el Self-taught clustering es un método que permite realizar el clustering de pequeñas colecciones de datos objetivo no etiquetados, con la ayuda de una gran cantidad de datos fuente no etiquetados. Este método ha demostrado ser más efectivo que los métodos de punta tradicionalmente utilizados, en los que los datos objetivo no son etiquetados de forma pertinente.\n",
    "\n",
    "### 3. Aprendizaje por transferencia transductiva o “Transductive Transfer Learning”:\n",
    "En este método, las tareas fuente y objetivo son similares pero sus campos correspondientes son diferentes en términos de datos o de distribuciones de probabilidad marginales.\n",
    "\n",
    "Por ejemplo, los modelos de NLP, como los que se utiliza para el etiquetado morfosintáctico de palabras, Part-Of-Speech Tagger (POS Tagger) en inglés, son generalmente entrenados y testeados con datos de actualidad como los del Wall Street Journal. Pueden ser adaptados a datos extraídos de redes sociales, cuyo contenido es diferente pero se asemeja al de los periódicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se aplica concretamente el Transfer Learning para la resolución de problemas de Deep Learning?\n",
    "\n",
    "Ahora que hemos definido el Transfer Learning, podemos enfocarnos en problemas de Deep Learning, que está teniendo un gran éxito últimamente.\n",
    "\n",
    "La utilización de métodos de Transfer Learning en Deep Learning consiste principalmente en explotar redes neuronales pre-entrenadas.\n",
    "\n",
    "Generalmente, estos modelos corresponden a algoritmos de alto rendimiento que han sido desarrollados y entrenados sobre grandes bases de datos y que son hoy de libre acceso.\n",
    "\n",
    "En este contexto, se pueden distinguir 2 tipos de estrategias :\n",
    "\n",
    "### 1. Utilización de modelos pre-entrenados como extractores de features :\n",
    "\n",
    "La arquitectura de estos modelos de Deep Learning se presenta frecuentemente bajo la forma de un compilado de capas de neuronas. Estas capas adquieren diferentes características en función del nivel en el que se sitúan. La última capa (generalmente una capa enteramente conectada, en el caso del aprendizaje supervisado), es utilizada para obtener el resultado final. La siguiente figura ilustra la arquitectura de un modelo de Deep Learning utilizado para la detección de gatos y perros. Mientras más profunda se sitúa la capa, más permite extraer features específicas.\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./Imagenes/07.png\", style=\"width:90%;\" >\n",
    "</figure>\n",
    "\n",
    "\n",
    "La idea es reutilizar una red pre-entrenada sin capa final. Esta nueva red funciona como un extractor de features fijas para realizar otras tareas.\n",
    "\n",
    "Para ilustrar esta estrategia, tomemos el caso en el que se desea crear un modelo capaz de identificar la especie de una flor a partir de su imagen. Para esto, será posible utilizar las primeras capas de un modelo de red neuronal convolutivo AlexNet, que fue inicialmente entrenado sobre la base de imágenes ImageNet para clasificar imágenes.\n",
    "\n",
    "### 2. Ajustes de modelos pre-entrenados\n",
    "\n",
    "Se trata de una técnica más compleja, en la que no solamente la última capa es reemplazada para realizar la clasificación o regresión, sino que también otras capas son re-entrenadas de manera selectiva. Las redes neuronales profundas son arquitecturas altamente configurables con diversos hiper-parámetros. Además, mientras que las primeras capas captaron características generales, las últimas capas se concentran principalmente en la tarea específica a cumplir, como lo muestra la siguiente figura:\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./Imagenes/08.png\", style=\"width:90%;\" >\n",
    "</figure>\n",
    "\n",
    "La idea es *congelar*, es decir fijar el peso de ciertas capas durante el entrenamiento y afinar el resto para responder al problema.\n",
    "\n",
    "Esta estrategia permite reutilizar los conocimientos en términos de arquitectura global de la red y explotar sus estados como punto de partida para el entrenamiento. Permite obtener mejores resultados en un tiempo de entrenamiento más corto.\n",
    "\n",
    "## Modelos mas utilizados\n",
    "\n",
    "Una de las exigencias fundamentales del aprendizaje por transferencia es la presencia de modelos que funcionen bien para las tareas fuente. Por suerte, existen varias arquitecturas de Deep Learning de punta que son hoy de libre acceso. Estas se extienden sobre diferentes campos como la visión por computadora o Computer Vision, y el Tratamiento Natural del Lenguaje o NLP, dos campos muy populares en Deep Learning.\n",
    "\n",
    "Entre los modelos más utilizados están:\n",
    "\n",
    "- Computer Vision : VGG-16, VGG-19, ResNet-50\n",
    "- NLP : Word2Vec, GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡Como podemos armar nuestro propio Data Set?\n",
    "\n",
    "1. Vamos a descargar una aplicación de Google que nos permite descargar todas las imágenes que tenemos en la página que estamos viendo: https://chrome.google.com/webstore/detail/download-all-images/ifipmflagepipjokmbdecpmjbibjnakm\n",
    "\n",
    "2. Vamos al buscardor de imágenes y buscamos todas aquellas imágenes que necesitemos para el proyecto.\n",
    "\n",
    "3. Presionamos en \"zip\", que es la extensión que se instaló en la parte superior derecha.\n",
    "\n",
    "4. En el explorador de windows, descomprimir los .zip y armar una carpeta por cada clase a clasificar. Hay que eliminar las imágenes que no sirvan, que no sean representativas de lo que queremos clasificar y todos aquellos archivos que no sean formato de imágen.\n",
    "\n",
    "5. Zipiar clas fotos (no la carpeta) y reservar para mas adelante\n",
    "\n",
    "6. Desde Colab, continuar con el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkfUii9l45Ex"
   },
   "outputs": [],
   "source": [
    "#Crear las carpetas para subir las imagenes\n",
    "!mkdir cuchillos\n",
    "!mkdir cucharas\n",
    "!mkdir tenedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmWHDM4N6BXT"
   },
   "outputs": [],
   "source": [
    "# Subir los zip en cada una de las carpetas, luego\n",
    "#Entrar en cada carpeta y descomprimir el archivo zip\n",
    "%cd /content/cuchillos\n",
    "!unzip cuchillos.zip\n",
    "%cd ..\n",
    "\n",
    "%cd /content/tenedores\n",
    "!unzip tenedores.zip\n",
    "%cd ..\n",
    "\n",
    "%cd /content/cucharas\n",
    "!unzip cucharas.zip\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8C8wQOFN6ZAS"
   },
   "outputs": [],
   "source": [
    "#Borrar los archivo ZIP\n",
    "!rm -rf /content/cucharas/cucharas.zip\n",
    "!rm -rf /content/cuchillos/cuchillos.zip\n",
    "!rm -rf /content/tenedores/tenedores.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nfH5aTP6js8",
    "outputId": "29320685-d82a-42ad-faf0-ea3147aa2a19"
   },
   "outputs": [],
   "source": [
    "#Mostrar cuantas imagenes tengo de cada categoria\n",
    "!ls /content/cucharas | wc -l \n",
    "!ls /content/cuchillos | wc -l \n",
    "!ls /content/tenedores | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "Y5XvYcwH6vGG",
    "outputId": "772f3ad4-8374-4f78-e06e-d5b686cb390f"
   },
   "outputs": [],
   "source": [
    "#Mostrar algunas imagenes con pyplot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "carpeta = '/content/cuchillos'\n",
    "imagenes = os.listdir(carpeta)\n",
    "\n",
    "for i, nombreimg in enumerate(imagenes[:25]):\n",
    "  plt.subplot(5,5,i+1)\n",
    "  imagen = mpimg.imread(carpeta + '/' + nombreimg)\n",
    "  plt.imshow(imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDjMjyGi7agS"
   },
   "outputs": [],
   "source": [
    "#Crear carpetas para hacer el set de datos\n",
    "\n",
    "!mkdir dataset\n",
    "!mkdir dataset/cuchillo\n",
    "!mkdir dataset/tenedor\n",
    "!mkdir dataset/cuchara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "box5_qnJ7l5q"
   },
   "outputs": [],
   "source": [
    "#Copiar imagenes que subimos a carpetas del dataset\n",
    "#Limitar para que todos tengan la misma cantidad de imagenes\n",
    "#maximo 103 (el num. menor de imagenes que subi)\n",
    "\n",
    "import shutil\n",
    "carpeta_fuente = '/content/cuchillos'\n",
    "carpeta_destino = '/content/dataset/cuchillo'\n",
    "\n",
    "imagenes = os.listdir(carpeta_fuente)\n",
    "\n",
    "for i, nombreimg in enumerate(imagenes):\n",
    "  if i < 103:\n",
    "    #Copia de la carpeta fuente a la destino\n",
    "    shutil.copy(carpeta_fuente + '/' + nombreimg, carpeta_destino + '/' + nombreimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oKaAjei8UoR"
   },
   "outputs": [],
   "source": [
    "carpeta_fuente = '/content/tenedores'\n",
    "carpeta_destino = '/content/dataset/tenedor'\n",
    "\n",
    "imagenes = os.listdir(carpeta_fuente)\n",
    "\n",
    "for i, nombreimg in enumerate(imagenes):\n",
    "  if i < 103:\n",
    "    #Copia de la carpeta fuente a la destino\n",
    "    shutil.copy(carpeta_fuente + '/' + nombreimg, carpeta_destino + '/' + nombreimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GljCc4xM8XF1"
   },
   "outputs": [],
   "source": [
    "carpeta_fuente = '/content/cucharas'\n",
    "carpeta_destino = '/content/dataset/cuchara'\n",
    "\n",
    "imagenes = os.listdir(carpeta_fuente)\n",
    "\n",
    "for i, nombreimg in enumerate(imagenes):\n",
    "  if i < 103:\n",
    "    #Copia de la carpeta fuente a la destino\n",
    "    shutil.copy(carpeta_fuente + '/' + nombreimg, carpeta_destino + '/' + nombreimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_KRXzdN8fjX",
    "outputId": "7960eefc-4dbd-4a8d-9163-f2f2ff04530e"
   },
   "outputs": [],
   "source": [
    "#Mostrar cuantas imagenes tengo de cada categoria en el dataset\n",
    "!ls /content/dataset/cuchara | wc -l\n",
    "!ls /content/dataset/cuchillo | wc -l\n",
    "!ls /content/dataset/tenedor | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "LtP_w0o_93Kg",
    "outputId": "87ba5950-d2a4-4be9-cd40-86289fd0c82c"
   },
   "outputs": [],
   "source": [
    "#Aumento de datos con ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "#Crear el dataset generador\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range = 30,\n",
    "    width_shift_range = 0.25,\n",
    "    height_shift_range = 0.25,\n",
    "    shear_range = 15,\n",
    "    zoom_range = [0.5, 1.5],\n",
    "    validation_split=0.2 #20% para pruebas\n",
    ")\n",
    "\n",
    "#Generadores para sets de entrenamiento y pruebas\n",
    "data_gen_entrenamiento = datagen.flow_from_directory('/content/dataset', \n",
    "                                                     target_size=(224,224),\n",
    "                                                     batch_size=32, \n",
    "                                                     shuffle=True, \n",
    "                                                     subset='training')\n",
    "data_gen_pruebas = datagen.flow_from_directory('/content/dataset', \n",
    "                                               target_size=(224,224),\n",
    "                                               batch_size=32, \n",
    "                                               shuffle=True, \n",
    "                                               subset='validation')\n",
    "\n",
    "#Imprimir 10 imagenes del generador de entrenamiento\n",
    "for imagen, etiqueta in data_gen_entrenamiento:\n",
    "  for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(imagen[i])\n",
    "  break\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-XXSY6Z_1YW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Traemos un modelo pre entrenado sin la ultima capa\n",
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobilenetv2 = hub.KerasLayer(url, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dvv6GVPpATt8"
   },
   "outputs": [],
   "source": [
    "#Congelar el modelo descargado para que no reentrene estas capas\n",
    "mobilenetv2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmDIA3FKAXpz"
   },
   "outputs": [],
   "source": [
    "# Reemplazamos la capa de salida por nuestra capa de salida\n",
    "modelo = tf.keras.Sequential([\n",
    "    mobilenetv2,\n",
    "    tf.keras.layers.Dense(3, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RNaQGnWAjpQ",
    "outputId": "e86e0094-4117-490c-cb7b-d7d2bc4e7dbf"
   },
   "outputs": [],
   "source": [
    "# vemos la arquitectura de nuestro modelo\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UfMugXKApYe"
   },
   "outputs": [],
   "source": [
    "#Compilar como siempre\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvIFkP-7Axnp",
    "outputId": "b5481099-0080-4b70-b766-205d8a04fd52"
   },
   "outputs": [],
   "source": [
    "#Entrenar el modelo\n",
    "EPOCAS = 50\n",
    "\n",
    "historial = modelo.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "WhM0WbPAFVLZ",
    "outputId": "4dbf8c60-300e-424c-9b4b-a306fd6b216a"
   },
   "outputs": [],
   "source": [
    "#Graficas de precisión\n",
    "acc = historial.history['accuracy']\n",
    "val_acc = historial.history['val_accuracy']\n",
    "\n",
    "loss = historial.history['loss']\n",
    "val_loss = historial.history['val_loss']\n",
    "\n",
    "rango_epocas = range(50)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(rango_epocas, acc, label='Precisión Entrenamiento')\n",
    "plt.plot(rango_epocas, val_acc, label='Precisión Pruebas')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Precisión de entrenamiento y pruebas')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rango_epocas, loss, label='Pérdida de entrenamiento')\n",
    "plt.plot(rango_epocas, val_loss, label='Pérdida de pruebas')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Pérdida de entrenamiento y pruebas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0Hng_7nGMXT"
   },
   "outputs": [],
   "source": [
    "#Categorizar una imagen de internet\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "\n",
    "def categorizar(url):\n",
    "  respuesta = requests.get(url)\n",
    "  img = Image.open(BytesIO(respuesta.content))\n",
    "  img = np.array(img).astype(float)/255\n",
    "\n",
    "  img = cv2.resize(img, (224,224))\n",
    "  prediccion = modelo.predict(img.reshape(-1, 224, 224, 3))\n",
    "  return np.argmax(prediccion[0], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCKEHF08Hh-D",
    "outputId": "86ffcc3c-7d37-403d-abd4-1e544a52173d"
   },
   "outputs": [],
   "source": [
    "#0 = cuchara, 1 = cuchillo, 2 = tenedor\n",
    "url = 'https://github.com/IngCarlaPezzone/Clase-Machine-Learning/blob/main/Clase%2016/cuchara.jpg?raw=true' #debe ser 0\n",
    "prediccion = categorizar (url)\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/IngCarlaPezzone/Clase-Machine-Learning/blob/main/Clase%2016/cuchillo.jpg?raw=true' #debe ser 1\n",
    "prediccion = categorizar (url)\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/IngCarlaPezzone/Clase-Machine-Learning/blob/main/Clase%2016/tenedor.jpg?raw=true' #debe ser 2\n",
    "prediccion = categorizar (url)\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TD6PPPWPeGEb"
   },
   "outputs": [],
   "source": [
    "#Crear la carpeta para exportarla a TF Serving\n",
    "!mkdir -p carpeta_salida/modelo_cocina/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbBmOwVbeKzs",
    "outputId": "3d56ca63-cdc2-41ec-94d4-8e25d435c0a4"
   },
   "outputs": [],
   "source": [
    "#Guardar el modelo en formato SavedModel\n",
    "modelo.save('carpeta_salida/modelo_cocina/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-CGKz9neN40",
    "outputId": "5b65e567-e5b8-410e-d8a7-13617f30175b"
   },
   "outputs": [],
   "source": [
    "#Hacerlo un zip para bajarlo y usarlo en otro lado\n",
    "!zip -r modelo_cocina.zip /content/carpeta_salida/modelo_cocina/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
