{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiciones\n",
    "\n",
    "## Contenidos\n",
    "\n",
    "- [1 - IA vs ML vs DL](#1)\n",
    "- [2 - ¿Qué es el ML?](#2)\n",
    "- [3 - Tipos de ML](#3)\n",
    "- [4 - Tareas de ML](#4)\n",
    "- [5 - Los datos](#5)\n",
    "- [6 - Tipo de datos](#6)\n",
    "- [7 - Principales problemas del ML](#7)\n",
    "- [8 - Librerías de Python para ML](#8)\n",
    "\n",
    "<a name='1'></a>\n",
    "## IA vs ML vs DL\n",
    "\n",
    "Definir la IA no es tarea fácil. Aquí algunos ejemplos.\n",
    "\n",
    "<span style=\"color:green\">\n",
    "\n",
    "> **La Inteligencia Artificial es el ámbito de estudio que confiere a los ordenadores la capacidad de aprender sin ser programados explícitamente (Arthur Samuel, 1959).**\n",
    "\n",
    "\n",
    "> **Un programa aprende de la experiencia E con respecto a la tarea T y medida de éxito P si su desempeño en T, medido por P, mejora con la experiencia E (Tom Michell, 1997).**</span>\n",
    "\n",
    "La IA es un campo de la ciencia cuyo origen precedo incluso a la invención de los ordenadores. Desde entonces, multitud de técnicas y algoritmos han sido desarrollados, desde el Perceptrón hasta las redes neuronales de hoy en día. \n",
    "\n",
    "![](./pics/ia_ml_dl.png)\n",
    "\n",
    "Dentro de la IA encontramos una familia de algoritmos conocida como *Machine Learning*. Estos algoritmos se caracterizan por ser capaces de aprender a llevar a cabo una tarea específica a partir de ejemplos. Dentro de este grupo encontramos una subcategoría de algoritmos conocida como *Deep Learning*, que no solo es capaz de aprender a partir de datos sino que además es capaz de hacerlo con mínima intervención humana (*feature engineering*).\n",
    "\n",
    "![](./pics/fe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## ¿Qué es el ML?\n",
    "\n",
    "El uso del ML es de especial utilidad en aquellas tareas en las que la programación \"tradicional\" (o software 1.0) falla, principalmente debido a la imposibilidad de desarrollar una serie de instrucciones capaz de resolver el problema. También es recomendable su uso en entornos cambiantes o a la hora de extraer información de grandes cantidades de datos. \n",
    "\n",
    "![](./pics/s20.png)\n",
    "\n",
    "Esto es debido a que, mientras que en el \"software 1.0\" el programador debe crear un programa (serie de instrucciones) para llevar a cabo una tarea, en el \"software 2.0\" (otro término atribuido al ML) será el mismo algoritmo el que aprenderá por sí mismo a resolver un problema a base de ejemplos. \n",
    "\n",
    "|   | Programación tradicional  | ML  | \n",
    "|---|---|---|\n",
    "| Programa  | Código escrito por el programador en un lenguaje  | Los datos  | \n",
    "| Compilación  | Traducción del programa a código máquina  | El modelo (y receta de entrenamiento)  | \n",
    "| Binario  | Ejecutable que el ordenador entiende  | Modelo entrando  | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Tipos de ML\n",
    "\n",
    "Podemos clasificar los diferentes algoritmos de ML en función de:\n",
    "\n",
    "1. **El proceso de entrenamiento:** supervisado, no supervisado (o semi-supervisado) y aprendizaje por refuerzo.\n",
    "2. **Su forma de aprender:** en modo *batch* o *online*. \n",
    "3. **Su funcionamiento:** basado en modelos o instancias.\n",
    "\n",
    "### Aprendizaje supervisado, no supervisado (o semi-supervisado) y aprendizaje por refuerzo\n",
    "\n",
    "#### Aprendizaje supervisado\n",
    "\n",
    "Es donde los algoritmos trabajan con datos “etiquetados” (labeled data), intentado encontrar una función que, dadas las variables de entrada (input data), les asigne la etiqueta de salida adecuada. El algoritmo se entrena con un “histórico” de datos y así “aprende” a asignar la etiqueta de salida adecuada a un nuevo valor, es decir, predice el valor de salida.\n",
    " \n",
    "Por ejemplo, un detector de spam, analiza el histórico de mensajes, viendo qué función puede representar, según los parámetros de entrada que se definan (el remitente, si el destinatario es individual o parte de una lista, si el asunto contiene determinados términos etc), la asignación de la etiqueta “spam” o “no es spam”. Una vez definida esta función, al introducir un nuevo mensaje no etiquetado, el algoritmo es capaz de asignarle la etiqueta correcta.\n",
    " \n",
    "El aprendizaje supervisado se suele usar en:\n",
    " \n",
    "- Problemas de clasificación (identificación de dígitos, diagnósticos, o detección de fraude de identidad).\n",
    "- Problemas de regresión (predicciones meteorológicas, de expectativa de vida, de crecimiento etc).\n",
    " \n",
    "Estos dos tipos principales de aprendizaje supervisado, clasificación y regresión, se distinguen por el tipo de variable objetivo. En los casos de clasificación, es de tipo categórico, mientras que, en los casos de regresión, la variable objetivo es de tipo numérico.\n",
    "\n",
    "#### Aprendizaje no supervisado: \n",
    "\n",
    "El aprendizaje no supervisado tiene lugar cuando no se dispone de datos “etiquetados” para el entrenamiento. Sólo conocemos los datos de entrada, pero no existen datos de salida que correspondan a un determinado input. Por tanto, sólo podemos describir la estructura de los datos, para intentar encontrar algún tipo de organización que simplifique el análisis. Por ello, tienen un carácter exploratorio.\n",
    "\n",
    "Por ejemplo, las tareas de clustering, buscan agrupamientos basados en similitudes, pero nada garantiza que éstas tengan algún significado o utilidad. En ocasiones, al explorar los datos sin un objetivo definido, se pueden encontrar [correlaciones curiosas](http://tylervigen.com/spurious-correlations), pero poco prácticas.\n",
    "\n",
    "El aprendizaje no supervisado se suele usar en problemas de clustering o de agrupamientos.\n",
    "\n",
    "#### Aprendizaje por refuerzo\n",
    "\n",
    "Este tipo aprendizaje se basa en mejorar la respuesta del modelo usando un proceso de retroalimentación. El algoritmo aprende observando el mundo que le rodea. Su información de entrada es el feedback o retroalimentación que obtiene del mundo exterior como respuesta a sus acciones. Por lo tanto, el sistema aprende a base de ensayo-error.\n",
    "\n",
    "No es un tipo de aprendizaje supervisado, porque no se basa estrictamente en un conjunto de datos  etiquetados, sino en la monitorización de la respuesta a las acciones tomadas. Tampoco es un aprendizaje no supervisado, ya que, cuando modelamos a nuestro «aprendiz»sabemos de antemano cuál es la recompensa esperada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## Tareas de ML\n",
    "\n",
    "Las principales tareas que podemos llevar a cabo con ML son: clasificación, regresión y *clustering*. Para cada tarea, existen numerosos algoritmos .\n",
    "\n",
    "![](./pics/tareas.png)\n",
    "\n",
    "### Algoritmos de clasificación\n",
    "\n",
    "Los algoritmos de clasificación se usan cuando el resultado deseado es una etiqueta discreta, en otras palabras, son útiles cuando la respuesta al problema cae dentro de un conjunto finito de resultados posibles.\n",
    "\n",
    "En el caso de que el modelo entrenado es para predecir cualquiera de las dos clases objetivos, verdadero o falso, por ejemplo, se le conoce como clasificación binaria. Algunos ejemplos de esto son: predecir si un alumno aprobará o no, predecir si un cliente comprará un producto nuevo o no.\n",
    "\n",
    "Por su parte, si tenemos que predecir más de dos clases objetivos, se le conoce como clasificación multicategoría. Un ejemplo de esto es predecir qué asignaturas un alumno tendrá las más clasificaciones. Este tipo de clasificación es útil para la segmentación del cliente, la categorización de imágenes y audio y análisis de texto para optimizar el sentiento del cliente.\n",
    "\n",
    "### Algoritmos de regresión\n",
    "\n",
    "La regresión es útil para predecir productos que son continuos, eso significa que la respuesta a su pregunta se presenta mediante una cantidad que puede determinarse de manera flexible en función de las entradas del modelo en lugar de limitarse a un conjunto de etiquetas. En algunos casos, el valor predicho se puede usar para identificar la relación lineal entre los atributos.\n",
    "\n",
    "La regresión lineal es el ejemplo más popular de un algoritmo de regresión, aunque a menudo se subestima debido a su relativa simplicidad, es un método versatil que se puede usar para predecir los precios de la vivienda, la probabilidad de que los clientes se desvién o los ingresos que un cliente generará.\n",
    "\n",
    "### Algoritmos de clustering\n",
    "\n",
    "Clustering es una técnica que implica la agrupación de puntos de datos. Dado un conjunto de puntos de datos, podemos utilizar un algoritmo de agrupación para clasificar cada punto de datos en un clúster específico. En teoría, los puntos de datos que están en el mismo clúster deben tener propiedades y/o características similares, mientras que los puntos de datos en diferentes clústeres deben tener propiedades y/o características muy diferentes. La agrupación es un método de Aprendizaje no Supervisado y es una técnica común para el análisis de datos estadísticos utilizada en muchos campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## Los datos\n",
    "\n",
    "El ML gira entorno a los datos. Como hemos visto anteriormente son la parte fundamental y dos conjuntos de datos distintos nos darán resultados muy diferentes aunque usemos el mismo modelo y receta de entrenamiento. Así pues, un buen entendimiento de los datos y cómo trabajar con ellos es crucial para tener éxito en aplicaciones de ML. De entre todas las cuestiones que hay que tener en cuenta, la separación de datos en conjuntos de entrenamiento, validación y test es quizás la más importante.\n",
    "\n",
    "![](./pics/datos.png)\n",
    "\n",
    "Así pues usaremos el conjunto de entrenamiento para entrenar nuestros modelos, el de validación para optimizar los hiperparámetros y el de test para generar las métricas finales. \n",
    "\n",
    "### Método Holdout (Retención)\n",
    "\n",
    "El método Holdout es el tipo de método más simple para evaluar un clasificador. En este método, el conjunto de datos (una colección de elementos de datos o ejemplos) se separa en dos conjuntos, denominados *Conjunto de entrenamiento* y *Conjunto de prueba*.\n",
    "\n",
    "### Método Validación cruzada\n",
    "\n",
    "La cross-validation o validación cruzada es un método que permite probar el rendimiento de un modelo predictivo de Machine Learning.\n",
    "\n",
    "En K-Fold Cross Validation, el conjunto de datos de entrenamiento se divide en dos partes: *entrenamiento* y *validación*, donde K representa la cantidad de pliegues u observaciones que se realizarán. Por ejemplo, si tenemos un conjunto de datos de entrenamiento con 20 eventos y elegimos la validación de 5 pliegues o cortes, esto dividiría el conjunto de datos de entrenamiento en 5 pliegues.\n",
    "\n",
    "![](./pics/cross_val.PNG)\n",
    "\n",
    "Tomar un conjunto de datos de entrenamiento con 20 eventos contra la validación cruzada de 4 veces produciría un conjunto de datos de prueba de 5 eventos y un conjunto de datos de entrenamiento de 15 eventos. Luego, este proceso se repite K veces (4) y la precisión resultante se promedia para producir una precisión general más realista del modelo que se está probando.\n",
    "\n",
    "IMPORTANTE: El “set de validación” no es realmente un tercer set si no que “vive” dentro del conjunto de Train. El set de validación se utilizará durante las iteraciones del conjunto de entrenamiento. este conjunto permite ajustar los parámetros del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## Tipo de datos\n",
    "\n",
    "No todos los datos son iguales. Esto significa que los datos generados por las aplicaciones de redes sociales son completamente diferentes de los datos generados por los sistemas de punto de venta o cadena de suministro. Los tipos de datos son:\n",
    "\n",
    "- **Estructurados:** los datos estructurados se clasifican con mayor frecuencia como datos cuantitativos, y es el tipo de datos que encajen perfectamente en filas y columnas fijos en bases de datos relacionales y hojas de cálculo. Los datos estructurados están muy organizados y se comprenden fácilmente mediante el lenguaje de máquina.\n",
    "- **No Estructurados:** se trata de conjuntos de datos (colecciones grandes típicas de archivos) que no se almacenan en un formato de base de datos estructurado. Los datos no estructurados tienen estructura interna, pero que no tienen una estructura pre-determinada. Por ejemplo, una imagen puede ser de cualquier cosa, no hay una estructura pre-determinada. En un fomulario, sin embargo, un computador puede pedir la fecha de nacimiento del usuario: esa fecha es un dato 'estructurado' porque el computador sabe que debe tener el formato MM/DD/AAAA. Si el campo de entrada del formulario dice \"comentarios\" y el usuario puede poner cualquier comentario, ese dato es no estructurado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## Principales problemas del ML\n",
    "\n",
    "El desarrollo de aplicaciones de ML no es fácil, y es que existen multitud de problemas a los que nos podemos enfrentar. Algunos ejemplos son: \n",
    "\n",
    "- Cantidad insuficiente de datos\n",
    "- Datos no representativos\n",
    "- Datos de baja calidad\n",
    "- Características en los datos irrelevantes\n",
    "- *Overfitting* o *underfitting*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "## Librerías de Python para ML\n",
    "\n",
    "Antes de entrar con los algoritmos y aplicaciones, vamos a hablar sobre el ecosistema de librerías existentes en `Python` para el `Machine Learning`, haciendo hincapié en aquellas más usadas por la comunidad y que también utilizaremos en en el curso.\n",
    "\n",
    "![](./pics/tools.png)\n",
    "\n",
    "En la imagen anterior puedes ver un resumen de las herramientas más usadas a día de hoy para `Machine Learning` con `Python`. Las herramientas con círculas las veeremos a lo largo del curso. Las herramientas sin círculo no las usaremos, pero vale la pena conocerlas ya que pueden serte útiles para algunas aplicaciones. \n",
    "\n",
    "En la base podemos encontrar `Python`, el lenguaje de programación base que todas las herramientas utilizan. Por encima encontramos herramientas como `Numpy`, para cálculo numérico, o `Jupyter`, para ejecutar nuestro código en `notebooks`. Por encima vemos herramientas basadas en `Numpy` como `Pandas`, para trabajar con datos tabulares, y `Matplotlib`, para generar gráficos en `Python`. Finalmente, en la última capa, encontramos `Scikit-Learn`, una de las librerías más utilizadas hoy en día para entrenar modelos de `Machine Learning` y `Tensorflow` para entrenar modelos de `Deep Learning`, al igual de `Pytorch`, pero que no es alcance de este curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "\n",
    "[**Python**](https://www.python.org/) se define como un **<span style=\"color:green\">“lenguaje de programación versátil, multiplataforma y multiparadigma que se destaca por su código legible y limpio”</span>**. Cuenta con una licencia de código abierto que permite su utilización en distintos contextos de forma gratuita.\n",
    "\n",
    "Su principal objetivo es la **automatización de procesos**, lo que hará de las tareas algo mucho más simple. En este sentido, Python crea un código con gran legibilidad, que ahorra tiempo y recursos. Uno de sus puntos fuertes es que “comprueba los errores sobre la marcha” para solucionarlos cuando afectan a la memoria, lo que mantiene la integridad de la matriz y evita las complicaciones a la hora de escribir el código.\n",
    "\n",
    "#### Usos de Python\n",
    "\n",
    "Uno de sus principales aliados es la **Inteligencia Artificial (AI)**, pero también se destaca en aplicaciones web y big data.\n",
    "\n",
    "- **Inteligencia Artificial:** al ser un lenguaje de escritura “rápido, escalable, robusto y de código abierto” permite plasmar ideas complejas con unas pocas líneas de código, lo que no es posible con otros lenguajes.\n",
    "- **Big Data:** el uso de Phyton se extendió en el análisis de datos y la extracción de información. Cuenta con bibliotecas de procesamiento de datos como Pydoop, Dask y Pyspark, que facilitan aún más la gestión de grandes volúmenes de información.\n",
    "- **Data Science:** Phyton incorpora motores numéricos como *Pandas* y *NumPy*, que son ampliamente utilizados por investigadores de todo el mundo. También se ocupa de los datos tabulares, matriciales y estadísticos, visualizados en bibliotecas populares como *Matplotlib* y *Seaborn*, lo que facilita la creación de una amplia variedad de gráficos y representaciones visuales de todo tipo.\n",
    "- **Frameworks de Pruebas:** es ideal para validar ideas o productos, ya que tiene muchos frameworks integrados que ayudan a depurar el código y ofrecen rápidos flujos de ejecución.\n",
    "- **Desarrollo Web:** con menos líneas de código se construyen back-end de aplicaciones web mucho más eficientes.\n",
    "- **Educación en Ciencias de la Computación:** su sintaxis simple permite a los estudiantes comenzar a adquirir habilidades valiosas para sus carreras. Además, admite varios paradigmas de programación como la imperativa, la funcional, la procedimental y la orientada a objetos.\n",
    "\n",
    "Python también se utiliza para obtener información de otros sitios web, lo que comúnmente se denomina “*scraping*”. Al mismo tiempo, puede aplicarse en el desarrollo de juegos y de softwares en general. Incluso tiene aplicaciones prometedoras en el campo médico que mejoran la capacidad de brindar diagnósticos y tratamientos precisos a los pacientes. En biología y bioinformática, puede aplicarse en el procesamiento de secuencias de ADN, la simulación de dinámica y genética de poblaciones y el modelado de estructuras bioquímicas. Otras áreas como astronomía, robótica, vehículos autónomos, negocios, meteorología y desarrollo de interfaces gráficas de usuario también se benefician con el uso de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anaconda y Jupiter\n",
    "\n",
    "[**Anaconda**](https://www.anaconda.com/) es una Suite de código abierto que abarca una serie de aplicaciones, librerías y conceptos diseñados para el desarrollo de la Ciencia de datos con Python. En líneas generales Anaconda Distribution es una distribucción de Python que funciona como un gestor de entorno, un gestor de paquetes y que posee una colección de +720 paquetes de código abierto.\n",
    "\n",
    "Un paquete es un pedazo de código que alguien ha escrito y que puede ser ejecutado y a menudo sirve para un propósito específico. Puedes considerar un paquete como una herramienta que puedes usar para tus propios proyectos.\n",
    "\n",
    "Dentro del Navegador de Anaconda encontramos varias aplicaciones que podemos utilizar, a continuación, se explican cada una de ellas, **Jupyter Notebook**. Este es un software de código abierto que permite a los Científicos de Datos realizar flujos de trabajo y realizar eficazmente soluciones científicas y computacionales. Con un énfasis en la presentación y la legibilidad, Jupyter Notebook es una opción inteligencia para proyectos de colaboración y publicaciones perspicaces. Jupyter Notebook es de código abierto y desarrollado en GitHub públicamente por la comunidad Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "[**NumPy**](https://numpy.org/) es un módulo de Python. El nombre es un acrónimo de Python Numérico. Es una librería que consiste en objetos de matrices multidimensionales y una colección de rutinas para procesar esas matrices.\n",
    "\n",
    "Es un módulo de extensión para Python, escrito en su mayor parte en C. Esto asegura que las funciones y funcionalidades matemáticas y numéricas precompiladas de NumPy garantizan una gran velocidad de ejecución.\n",
    "\n",
    "NumPy es un paquete de procesamiento de matrices de uso general. Proporciona un objeto de matriz multidimensional de alto rendimiento, y herramientas para trabajar con estas matrices. Es el paquete fundamental para la computación científica con Python. Además de sus obvios usos científicos, NumPy también puede ser usado como un eficiente contenedor multidimensional de datos genéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "[**Pandas**](https://pandas.pydata.org/) se deriva del término Panel Data, un término econométrico para conjuntos de datos que incluyen observaciones en múltiples períodos de tiempo para los mismos individuos.\n",
    "\n",
    "Es una librería de código abierto de Python que proporciona herramientas de análisis y manipulación de datos de alto rendimiento utilizando sus potentes estructuras de datos.\n",
    "\n",
    "Esta librería se desarrolló debido a la necesidad de tener una herramienta flexible de alto rendimiento para el análisis de datos. Anteriormente Python se utilizaba para la manipulación y preparación de datos por lo que no era utilizado para Machine Learning, Pandas resolvió este problema. Usando esta librería podemos lograr cinco pasos típicos en el procesamiento y análisis de datos, independientemente del origen de los datos: cargar, preparar, manipular, modelar y analizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib\n",
    "\n",
    "[**Matplotlib**](https://matplotlib.org/) es una librería de trazado utilizada para gráficos 2D en lenguaje de programación Python, es muy flexible y tiene muchos valores predeterminados incorporados que te ayudarán muchísimo en tú trabajo. Produce figuras de calidad de publicación en una variedad de formatos impresos y entornos interactivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn\n",
    "\n",
    "[**Scikit-Learn**](https://scikit-learn.org/stable/) es una biblioteca para aprendizaje automático de software libre para el lenguaje de programación Python. Incluye varios algoritmos de clasificación, regresión y análisis de grupos entre los cuales están máquinas de vectores de soporte, bosques aleatorios, Gradient boosting, K-means y DBSCAN. Está diseñada para interoperar con las bibliotecas numéricas y científicas NumPy y SciPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de separación de datos\n",
    "\n",
    "Veamos en código python usando la librería scikit-learn como es el procedimiento general para hacer el cross-validation con K-Folds.\n",
    "\n",
    "Como este data set es pequeño y esta pre-procesado no vamos a ver realmente la utilidad del cross validation, pero sí vamos a recorrer los pasos generales para aplicarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traemos los datos del data set iris\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ver de que se trata este data set\n",
    "\n",
    "# Vemos como estan guardados estan guardados los ejemplos\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# podemos ver la información del data set\n",
    "print(iris[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos como X a los datos\n",
    "X = iris[\"data\"]\n",
    "\n",
    "# Visualizamos los primeros 5 ejemplos\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos como y a las etiquetas\n",
    "y = iris[\"target\"]\n",
    "\n",
    "# Visualizamos las etiquetas de los primeros 5 ejemplos\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los nombres de las etiquetas son:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Los nombres de las características son:\n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Vemos cuales son los nombres de las eqtiquetas\n",
    "nombres_etiquetas = iris[\"target_names\"]\n",
    "print('Los nombres de las etiquetas son:\\n', nombres_etiquetas)\n",
    "\n",
    "#Vemos cuales son los nombres de las características\n",
    "nombres_características = iris[\"feature_names\"]\n",
    "print('\\nLos nombres de las características son:\\n', nombres_características)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el data set en train y test (80-20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, \n",
    "                                                    iris.target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de datos en Entrenamiento: (120, 4)\n",
      "Forma de datos en Testeo: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Forma de datos en Entrenamiento:', X_train.shape)\n",
    "print('Forma de datos en Testeo:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un modelo de Regresión Logística (podría ser cualquiera)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrenamos con los datos de Train\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrica del modelo:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la métrica del modelo entrenado\n",
    "score = clf.score(X_train,y_train)\n",
    "print(\"Metrica del modelo: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos Cross-Validation usando K-folds con 5 splits\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas cross_validation: \n",
      " [0.91666667 0.91666667 0.83333333 1.         1.         1.\n",
      " 1.         1.         0.91666667 0.91666667]\n"
     ]
    }
   ],
   "source": [
    "# Recalculamos la métrica para la validación cruzada\n",
    "scores = cross_val_score(clf, \n",
    "                         X_train, \n",
    "                         y_train, \n",
    "                         cv=kf,\n",
    "                         scoring=\"accuracy\")\n",
    "print(\"Metricas cross_validation: \\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de cross_validation 0.95\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el valor medio de la métrica entre los trozos\n",
    "# del cross validation\n",
    "print(\"Media de cross_validation\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre el set de testeo\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrica en Test 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la métrica para la prediccion\n",
    "score_pred = metrics.accuracy_score(y_test, preds)\n",
    "print(\"Metrica en Test\", score_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-principiante]",
   "language": "python",
   "name": "conda-env-.conda-principiante-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
