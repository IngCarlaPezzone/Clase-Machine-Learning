{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01581c7-3db4-4e4e-9683-5ab3b7308b44",
   "metadata": {},
   "source": [
    "## ¿Qué es clustering (agrupamiento)\n",
    "\n",
    "Un algoritmo de clustering examina una serie de puntos de datos y encuentra automáticamente los puntos de datos que están relacionados o son similares entre sí. \n",
    "\n",
    "## Aprendizaje Supervisado vs Aprendizaje No supervisado\n",
    "\n",
    "### Aprendizaje supervisado\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/01.png\"   style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Dado un conjunto de datos como este con las características $x_1$ y $x_2$. Con el aprendizaje supervisado, teníamos un conjunto de entrenamiento con las **características de entrada** $x$, así como las **etiquetas** $y$. Podríamos trazar un conjunto de datos como este y ajustar, digamos, un algoritmo de *regresión logística* o una *red neuronal* para aprender un límite de decisión como este. \n",
    "\n",
    "En el aprendizaje supervisado, el conjunto de datos incluye tanto las entradas $x$ como las salidas objetivo $y$. \n",
    "\n",
    "### Aprendizaje no supervisado\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/02.png\"   style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "En cambio, en el aprendizaje no supervisado, se da un conjunto de datos como éste con sólo $x$, pero no las etiquetas o las etiquetas objetivo $y$. Por eso, cuando trazo un conjunto de datos, se ve así, con sólo puntos en lugar de dos clases denotadas por las $x$ y las *o*. Como no tenemos las etiquetas objetivo $y$, no podemos decirle al algoritmo cuál es la \"*respuesta correcta, y*\" que queremos predecir. En su lugar, vamos a pedir al algoritmo que encuentre algo interesante sobre los datos, es decir, que encuentre alguna estructura interesante sobre estos datos. \n",
    "\n",
    "Pero el primer algoritmo de aprendizaje no supervisado que se aprende se llama algoritmo de agrupación (**clustering**), que busca un tipo particular de estructura en los datos. Es decir, mira el conjunto de datos como este y trata de ver si se puede agrupar en **clusters**, es decir, grupos de puntos que son similares entre sí. Un algoritmo de clustering, en este caso, podría encontrar que este conjunto de datos se compone de datos de dos clusters que se muestran aquí. \n",
    "\n",
    "## Aplicaciones de clustering\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/03.png\"   style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "- **Agrupación de artículos de noticias** similares, como la historia sobre los Pandas.\n",
    "- **Segmentación del mercado** para agrupar usuarios según su interes.\n",
    "- Para **analizar datos de ADN**, donde se observan los datos de expresión genética de diferentes individuos y se intenta agruparlos en personas que presentan rasgos similares. \n",
    "- La **astronomía y la exploración espacial**. Por ejemplo, los astrónomos que utilizan el clustering para el análisis de datos astronómicos con el fin de agrupar cuerpos en el espacio para su propio análisis de lo que ocurre en el espacio. Una de las aplicaciones que me pareció fascinante fue la de los astrónomos que utilizan el clustering para agrupar cuerpos para averiguar cuáles forman una galaxia o cuáles forman estructuras coherentes en el espacio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37266c6c-26eb-4258-8cf3-5345eaeac061",
   "metadata": {},
   "source": [
    "## Intuición K-means\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/04.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí he trazado un conjunto de datos con 30 ejemplos de entrenamiento sin etiquetar. Y lo que nos gusta hacer es ejecutar K-means en este conjunto de datos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f302519-d0ff-47e6-985b-3951565191ad",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/05.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "**Paso 0**: Lo primero que hace el algoritmo K-means es tomar una conjetura al azar sobre dónde podrían estar los centros de los dos clusters que se le pide que encuentre. En este ejemplo voy a pedirle que trate de encontrar dos clusters. Más adelante hablaremos de cómo decidir cuántos conglomerados encontrar. Pero el primer paso es elegir al azar dos puntos, que he mostrado aquí como una cruz roja y una cruz azul, en los que podrían ser los centros de dos clusters diferentes. Esto es sólo una conjetura inicial al azar y no son particularmente buenas conjeturas. Pero es un comienzo. \n",
    "\n",
    "\n",
    "K-means hará repetidamente dos cosas diferentes. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/06.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "**Paso 1**: asignar puntos a los centros de los clusters, esto es, va a ir a través de cada uno de estos puntos y mirar si está más cerca de la cruz roja o de la cruz azul, irá a través de todos estos ejemplos, de $x^{(1)}$ a $x^{(30)}$, mis 30 puntos de datos. Y para cada uno de ellos comprobará si está más cerca del centroide del cluster rojo, o si está más cerca del centroide del cluster azul. Y asignará cada uno de estos puntos al centroide del clúster que esté más cerca.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/07.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "**Paso2**: mirará todos los puntos rojos y tomará un promedio de ellos. Y moverá la cruz roja a lo que sea la ubicación promedio de los puntos rojos. Y así la cruz roja, que es el centroide del grupo rojo se moverá a un nuevo lugar. Y luego hacemos lo mismo para todos los puntos azules. Mira todos los puntos azules, y toma un promedio de ellos, y mueve la cruz azul. Así que ahora tienes una nueva ubicación para el centroide del clúster azul también. \n",
    "\n",
    "*Repetimos*:\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/08.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora que tienes estas nuevas y esperemos que ligeramente mejoradas suposiciones para las ubicaciones de los centros de los clusters, vamos a mirar a través de todos los 30 ejemplos de entrenamiento de nuevo. Y comprobaremos para cada uno de ellos, si está más cerca del centroide del cluster rojo o del azul para las nuevas ubicaciones. Y entonces vamos a asociar que se indican por el color de nuevo, cada punto a la más cercana centroide del clúster. Y si haces eso, ves que los puntos cambian de color. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/09.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "Así que si vamos y asociamos cada punto con los centroides de los clusters más cercanos, terminamos con esto. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efac674-0793-4807-90cc-496a065527c0",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/10.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "Y luego simplemente repetimos parte 2 de K-means de nuevo. Que es mirar todos los puntos rojos y calcular el promedio. Y también mirar todos los puntos azules y calcular la ubicación promedio de todos los puntos azules. Y resulta que terminas moviendo la cruz roja hacia allá y la azul hacia acá. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5e8db-8410-4e7f-8f5a-6d4b8425360b",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/11.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "Y repetimos estos dos pasos, es decir, mirar cada punto y asignarlo al centroide del clúster más cercano y luego también mover cada centroide del clúster a la media de todos los puntos con el mismo color. Si sigues haciendo estos dos pasos, verás que no hay más cambios en los colores de los puntos o en las ubicaciones de los centros de los clusters. Y esto significa que en este punto el algoritmo de clustering de K-means ha **convergido**. Porque aplicando esos dos pasos una y otra vez, no se producen más cambios ni en la asignación de puntos a los centroides ni en la ubicación de los centroides de los clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982aa487-62ab-4be7-b116-22fbcdfd6715",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona K-means?\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/12.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "El primer paso es **inicializar aleatoriamente K centros de cluster**. $\\mu$ representa la ubicación para la cruz roja y para la cruz azul correspondientes a los dos centros de cluster. Son vectores que tienen la misma dimensión que sus ejemplos de entrenamiento. \n",
    "\n",
    "Una vez inicializados aleatoriamente los K centros de cluster, K-means llevará a cabo repetidamente los paso 1 y 2 descriptos anteriormente. \n",
    "\n",
    "El primer paso es **asignar los puntos a los clusters**, los centroides, es decir, colorear cada uno de los puntos, ya sea rojo o azul, lo que corresponde a asignarlos a los centroides del cluster rojo o azul. Esto significa que para $i=1$ a través de $m$ ejemplos de entrenamiento, vamos a establecer $c^{(i)}$ para ser igual al índice, que puede ser cualquier cosa de uno a K del centroide del clúster más cercano al ejemplo de entrenamiento $x^{(i)}$. \n",
    "\n",
    "Matemáticamente se puede escribir esto como el cálculo de la distancia entre $x^{(i)}$ y $\\mu_k$. En matemáticas, la distancia entre dos puntos a menudo se escribe así. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/13.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "\n",
    "También se denomina norma L2. Lo que se quiere encontrar es el valor de $k$ que minimiza esto, porque eso corresponde al centroide del cluster $\\mu_k$ que está más cerca del ejemplo de entrenamiento $x^{(i)}$. Entonces el valor de $k$ que minimiza esto es lo que se establece en $c^{(i)}$. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/14.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "Cuando se implementa este algoritmo, se encuentra que en realidad es un poco más conveniente minimizar la distancia cuadrada porque el centroide del clúster con la menor distancia cuadrada debe ser el mismo que el centroide del clúster con la menor distancia. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/15.png\"   style=\"width:40%;\" >\n",
    "</figure>\n",
    "\n",
    "El segundo paso es **mover los centroides de los clusters**. Lo que significa que la $k=K$, el número de clusters. Vamos a establecer que la ubicación del centroide del clúster se actualice para que sea el promedio o la media de los puntos asignados a ese clúster $k$. Concretamente, lo que esto significa es que miraremos todos estos puntos rojos, digamos, y miraremos su posición en el eje horizontal y miraremos el valor de la primera característica $x^{(1)}$, y lo promediaremos. Calcula también el valor medio en el eje vertical. Después de calcular esos dos promedios, se encuentra que la media está aquí (líneas pnteadas rojo y azul), por lo que $\\mu_1$, que es la ubicación que el centroide del clúster rojo se actualiza en la intersección de las líneas punteadas rojas. Del mismo modo, miraremos todos los puntos que estaban coloreados en azul, y computa la media del valor en el eje horizontal, la media de su característica $x^{(1)}$. Calcula la media de la característica $x^{(2)}$. Esos dos promedios te dan la nueva ubicación del centroide del cluster azul, que por lo tanto se mueve hacia la intersección de las líneas punteadas. \n",
    "\n",
    "### Caso especial: caso esquina\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/16.png\"   style=\"width:30%;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora bien, hay un caso de esquina de este algoritmo, que es lo que ocurre si un cluster tiene cero ejemplos de entrenamiento asignados a él. En ese caso, el segundo paso, sería tratar de calcular el promedio de los puntos cero. Eso no está bien definido. Si eso ocurre, lo más común es eliminar ese cluster. Terminas con $K-1$ clusters. \n",
    "\n",
    "O si realmente se necesitan K clusters, una alternativa sería *reiniciar aleatoriamente el centroide de ese cluster* y esperar que se le asignen al menos algunos puntos la próxima vez. Pero en realidad es más común cuando se ejecuta K-means eliminar un cluster si no se le asignan puntos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34d380-f5eb-4d5d-bc6f-90e9a4b9d91b",
   "metadata": {},
   "source": [
    "### Optimización objetivo\n",
    "\n",
    "Vimos anteriormente, que los algoritmos de aprendizaje supervisado toman un conjunto de entrenamiento planteando una función de coste. Y luego utilizando el descenso gradual o algunos otros algoritmos para optimizar esa función de coste. \n",
    "\n",
    "Resulta que el algoritmo de K-means también está optimizando una función de coste específica. \n",
    "\n",
    "Recordemos la notación:\n",
    "\n",
    "- $c^{(i)}$: es el índice del clúster, de 1 a K según el ejemplo que este asignado en el momento.\n",
    "- $\\mu_k$: es el centroide del clúster k.\n",
    "- $\\mu_{c^{(i)}}$: es el centroide del clúster al que se ha asignado el ejemplo x^{(i)}\n",
    "\n",
    "La función de coste $J$, que es una función de $c^{(1)}$ a $c^{(m)}$ y de las ubicaciones $\\mu_1$ a $\\mu_k$, es la distancia cuadrada promedio entre cada ejemplo de entrenamiento $x^{(i)}$ y la ubicación del centroide del cluster al que se ha asignado el ejemplo de entrenamiento. A\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/17.png\"   style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Trata de encontrar asignaciones de puntos de centroides de clusters así como encontrar ubicaciones de centroides de clusters que *minimicen* la distancia al cuadrado. Así que si quieres minimizar esta distancia o la distancia cuadrada, lo que debes hacer es asignar $x^{(i)}$ más cercano.\n",
    "\n",
    "Por cierto, esta función de coste J también tiene un nombre en la literatura se llama la **función de distorsión**. \n",
    "\n",
    "Así que el hecho de que el algoritmo K-means esté optimizando una función de coste J significa que está garantizado que converja, es decir, en cada iteración la función de coste de distorsión debería *bajar o permanecer igual*. Pero si alguna vez sube, eso significa que hay un error en el código, nunca debería subir porque cada paso de K significa que se establece el valor $c^{(i)}$ y $\\mu_k$ para tratar de reducir la función de coste. \n",
    "\n",
    "Además, si la función de coste deja de bajar, eso también te da una forma de probar si K-means ha convergido. Una vez que hay una sola duración donde se mantiene igual. Eso suele significar que K-means ha convergido y deberías dejar de ejecutarlo. Y la función de coste de la distorsión está bajando muy, muy lentamente, también podrías decir simplemente que esto es lo suficientemente bueno y no gastar aún más ciclos de computación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e011af-54f2-4cd4-ac84-15ea8903889f",
   "metadata": {},
   "source": [
    "### Inicialización\n",
    "\n",
    "Dijimos arriba que el \"Paso 0\" fue elegir ubicaciones aleatorias como las conjeturas iniciales para los centros de cluster. Pero ¿cómo se toma realmente esa conjetura aleatoria?. \n",
    "\n",
    "Cuando se ejecuta K-means se debe elegir siempre el número de centros de cluster $K$ para que sea menor a los ejemplos de entrenamiento $m$. No tiene sentido tener $K$ mayor que $m$ porque entonces no habrá suficientes ejemplos de entrenamiento para tener al menos un ejemplo de entrenamiento por centroides de cluster. Así que en nuestro ejemplo anterior teníamos $K=2$ y $m=30$.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/18.png\"   style=\"width:30%;\" >\n",
    "</figure>\n",
    "\n",
    "Para elegir los centros de los clusters, la forma más común es elegir aleatoriamente $K$ ejemplos de entrenamiento. Así que aquí tenemos un conjunto de entrenamiento en el que si yo escogiera al azar dos ejemplos de entrenamiento, quizás acabaría escogiendo como en la figura. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c849c-d1f8-41f3-b78c-04b7af2abf47",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/19.png\"   style=\"width:30%;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora bien, con este método existe la posibilidad de que acabes con una inicialización de los centroides de los clusters como la de esta figura. Y dependiendo de cómo elijas los centroides centrales iniciales aleatorios acabas eligiendo un conjunto de clousters diferentes para tu conjunto de datos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf8248-0d8e-4c33-8fb2-a6cc161ec4ad",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/20.png\"   style=\"width:30%;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos un ejemplo un poco más complejo, en el que vamos a mirar este conjunto de datos y tratar de encontrar tres clusters para que $K=3$ en estos datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c326d927-b611-407c-9473-68e7a68e610e",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/21.png\"   style=\"width:30%;\" >\n",
    "</figure>\n",
    "\n",
    "Si ejecutáramos K-means con una inicialización aleatoria del centroide del cluster, podríamos obtener este resultado aquí y esto parece una opción bastante buena. Una agrupación bastante buena de los datos en tres clusters diferentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80a4f0-d5a7-4f8e-b489-8baa6f07c49c",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/22.png\"   style=\"width:30%;\" >\n",
    "</figure>\n",
    "\n",
    "Pero con una inicialización diferente, digamos que usted ha inicializado dos de los centros de cluster dentro de el grupo de puntos de abajo. Y uno dentro del grupo de puntos de arriba, después de correr k significa que usted podría terminar con esta agrupación, que no se ve tan bien. Y esto resulta ser un **óptimo local**, en el que K-means está tratando de minimizar la *función de costo de distorsión*, esa función de costo $J(C)$. Pero con esta elección menos afortunada de inicialización aleatoria, acaba de quedarse atascado en un mínimo local.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fef29-f8dc-4e1e-818e-f7456b83ad99",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/23.png\"   style=\"width:30%;\" >\n",
    "</figure>\n",
    "\n",
    "Y aquí tenemos otro ejemplo de mínimo local, en el que una inicialización aleatoria diferente llegó a encontrar esta agrupación de los datos en tres clusters, que de nuevo no parece tan buena como la primeroa que viste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26268b50-efb6-48b6-a84e-66df323e7e32",
   "metadata": {},
   "source": [
    "Otra cosa que podrías hacer con el algoritmo de K-means es ejecutarlo múltiples veces y luego tratar de encontrar el mejor óptimo local.\n",
    "\n",
    "Y resulta que si se ejecuta K-means tres veces digamos, y termina con estos tres agrupamientos distintos. Entonces una forma de elegir entre estas tres soluciones, es calcular la función de coste J para estas tres soluciones, las tres opciones de clusters encontradas por K-means. Y luego elegir una de estas tres según la que nos dé el *menor valor de la función de coste J*.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/24.png\"   style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Y de hecho, si miras esta agrupación de aquí arriba, esta cruz verde tiene distancias cuadradas relativamente pequeñas, todos los puntos verdes. La cruz roja tiene distancias relativamente pequeñas y puntos rojos y de forma similar la cruz azul. Y así la función de coste $J$ será relativamente pequeña para este ejemplo de arriba. \n",
    "\n",
    "Pero en el gráfico de abajo a la izquierda, la cruz azul tiene distancias más grandes a todos los puntos azules. Y en el gráfico de abajo a la derecha, la cruz roja tiene mayores distancias a todos los puntos rojos, por lo que la función de coste $J$, para estos ejemplos de abajo sería mayor. Por lo que si eliges entre estas tres opciones, la que tenga la *menor distorsión* de la función de coste $J$, acabarás seleccionando esta elección de los centros de los clusters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859131f-6a28-464d-883b-8799b445fe6f",
   "metadata": {},
   "source": [
    "### ¿Cómo elegir el número de clusters?\n",
    "\n",
    "\n",
    "El algoritmo de k-means requiere como una de sus entradas, $K$, el *número de clusters* que quieres que encuentre.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/25.png\"   style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "\n",
    "Para muchos problemas de clustering, el valor correcto de $K$ es realmente ambiguo. Si mostrara a diferentes personas el mismo conjunto de datos y les preguntara, ¿cuántos clústeres ve usted? Definitivamente habrá personas que dirán que parece que hay dos clusters distintos y tendrán razón (azul). También habría otros que verían en realidad cuatro clusters distintos (rojo). También tendrían razón. \n",
    "\n",
    "Dado que el clustering es un algoritmo de aprendizaje no supervisado, no se dan las respuestas correctas en forma de etiquetas específicas para tratar de replicar. Hay muchas aplicaciones en las que los datos en sí no dan un indicador claro de cuántos clusters hay en ellos. \n",
    "\n",
    "Hay algunas técnicas para tratar de elegir automáticamente el número de clusters a utilizar para una determinada aplicación. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/26.png\"   style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Pero una forma de intentar elegir el valor de $K$ se llama el **método del codo** y lo que hace es ejecutar K-means con una variedad de valores de $K$ y trazar la función de coste o la función de distorsión $J$ como una función del número de clusters. Lo que se encuentra es que cuando se tienen muy pocos clusters, digamos un conglomerado, la función de distorsión o la función de costo $J$ será alta y a medida que se aumenta el número de cluster, bajará, tal vez como la figura, y parece que la función de costo está disminuyendo rápidamente hasta que llegamos a tres clusters pero la disminución es más lenta después de eso. Escojamos $K=3$. A esto se le llama codo, por cierto, porque piensa que es análogo a esa es tu mano y ese es tu codo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/27.png\"   style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Graficar la función de costo como una función de K podría ayudar, podría ayudarte a ganar algo de conocimiento. Personalmente, casi nunca uso el método del codo para elegir el número correcto de clusters porque creo que para muchas aplicaciones, el número correcto de cluster es realmente ambiguo y encuentras que muchas funciones de coste se parecen a esto con sólo disminuciones suaves y no tiene un \"*codo*\" claro para elegir $K$. \n",
    "\n",
    "Por cierto, una técnica que no funciona es la de elegir $K$ para minimizar la función de coste $J$, porque al hacerlo, casi siempre se elige el mayor valor posible de $K$, ya que tener más clusters casi siempre reducirá la función de coste $J$. Elegir $K$ para minimizar la función de coste $J$ no es una buena técnica. \n",
    "\n",
    "\n",
    "A menudo se ejecuta K-means con el fin de obtener clusters para utilizarlos posteriormente o para algún propósito posterior. Es decir, vas a tomar los clusters y hacer algo con esos clusters. Lo que se recomienda hacer es evaluar K-means en función de su rendimiento para ese propósito posterior. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/28.png\"   style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Permítanme ilustrar el ejemplo del tamaño de las camisetas. Una cosa que podrías hacer es ejecutar K-means en este conjunto de datos para encontrar los clusters, en cuyo caso podrías encontrar clusters como el de la izquierda y esto sería cómo dimensionar tus camisetas pequeñas (S), medianas (M) y grandes (L), pero ¿cuántas tallas de camisetas debería haber? Pues es ambiguo. \n",
    "\n",
    "Si también ejecutaras K-means con cinco clusters, podrías obtener clusters como la izquierda. Esto permitiría clasificar las camisetas según la talla extra pequeña (XS), pequeña (S), mediana (M), grande (L) y extra grande (XL). \n",
    "\n",
    "Ambas son agrupaciones completamente válidas y muy buenas de los datos en clusters, pero si usted quiere usar tres clusters o cinco clusters ahora puede decidir en base a lo que tiene sentido para su negocio de camisetas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
